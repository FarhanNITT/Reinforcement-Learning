# Objective:
In this project, we implemented two model-free reinforcement learning algorithms. The first algorithm is Monte Carlo (MC), which includes both the first-visit on-policy MC prediction and on-policy MC control for the game of [blackjack](https://gymnasium.farama.org/environments/toy_text/blackjack/). The second algorithm is Temporal-Difference (TD), featuring Sarsa (on-policy) and Q-Learning (off-policy) applied to the [cliff walking](https://gymnasium.farama.org/environments/toy_text/cliff_walking/) problem.

The files mc_test.py and td_test.py function as test suites for evaluating the algorithms. To perform the tests, run the command "nosetests3 -v mc_test.py" in the terminal for Monte Carlo, and "nosetests3 -v td_test.py" for Temporal Difference, each separately. Ensure that both mc.py and mc_test.py are in the same directory, and similarly, td.py should be in the same directory as td_test.py.
